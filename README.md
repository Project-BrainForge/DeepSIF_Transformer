# DeepSIF Transformer

A PyTorch implementation of DeepSIF with Transformer architecture replacing LSTM for temporal modeling. This project uses labeled EEG dataset for source localization tasks.

## Overview

This project adapts the DeepSIF (Deep Source Imaging Framework) model by replacing the LSTM-based temporal module with a Transformer encoder. The model takes EEG sensor data as input and reconstructs the source-space activity.

### Key Features

- **Transformer-based temporal modeling**: Replaces LSTM with multi-head attention mechanism
- **Labeled dataset support**: Works with pre-labeled EEG-source pairs
- **Flexible architecture**: Supports both LSTM and Transformer models
- **Comprehensive evaluation**: Includes source localization and correlation metrics

## Dataset Format

This project works with pre-processed labeled dataset files (generated by `extract_labeled_data.py`).
Each `.mat` file contains:
- `eeg_data`: (500, 75) - Pre-processed EEG sensor data (500 time points, 75 sensors)
- `source_data`: (500, 994) - Pre-processed source space ground truth (500 time points, 994 sources)  
- `labels`: Active source region indices (no padding)
- `index`: Sample index
- `snr`: Signal-to-noise ratio

**Note**: The data is already processed (normalized, noise added, forward modeling applied) by the extraction script, so no additional processing is needed.

## Installation

1. Clone the repository:
```bash
git clone <repository-url>
cd DeepSIF_Transformer
```

2. Install dependencies:
```bash
pip install -r requirements.txt
```

3. Test the implementation:
```bash
python demo.py
```

4. Test evaluation scripts (after training):
```bash
python test_evaluation.py
```

## üîß Version Control & Git Setup

This project includes a comprehensive `.gitignore` file configured for ML projects:

**Automatically Ignored:**
- üìÅ Data directories (`labeled_dataset/`, `extracted_data/`, `source_collections/`)
- ü§ñ Model files (`*.pth`, `*.pth.tar`, `model_result/`) 
- üìã Log files (`*.log`, training logs)
- üêç Python cache (`__pycache__/`, `*.pyc`)
- üåê Virtual environments (`venv/`, `env/`)
- üíª IDE files (`.vscode/`, `.idea/`)
- üóÇÔ∏è Large data files (`*.mat` - except small config files)

**Git Commands:**
```bash
# Check what will be tracked vs ignored
python check_git_status.py

# Initialize repository (if not done)
git init

# Add only source code and configs
git add *.py *.md .gitignore requirements.txt

# Commit
git commit -m "Initial commit: DeepSIF Transformer"

# Check status and ignored files
git status --ignored
```

**‚ö†Ô∏è Important**: Never commit large data files or trained models to git! The `.gitignore` handles this automatically.

3. Generate labeled dataset (if not already done):
```bash
# From your data-generation directory
python extract_labeled_data.py --dataset_path source/train_sample_source1.mat \
                               --output_dir labeled_dataset \
                               --forward_model anatomy/leadfield_75_20k.mat
```

4. Set up directory structure:
```
DeepSIF_Transformer/
‚îú‚îÄ‚îÄ labeled_dataset/        # Pre-processed sample_*.mat files
‚îú‚îÄ‚îÄ anatomy/               # Forward matrices (optional for training)
‚îú‚îÄ‚îÄ model_result/          # Training outputs
‚îú‚îÄ‚îÄ results/               # Evaluation outputs
‚îú‚îÄ‚îÄ main.py                # Main training script
‚îú‚îÄ‚îÄ eval_real.py           # Evaluation script
‚îú‚îÄ‚îÄ network.py             # Model architectures
‚îú‚îÄ‚îÄ loaders.py             # Data loaders
‚îî‚îÄ‚îÄ utils.py               # Utility functions
```

## Usage

### Training

#### Optimized Training (Recommended)

Train with the optimized configuration and enhanced logging:

```bash
# Standard training with optimal settings
python train_optimized.py --data_path labeled_dataset --model_id stable_v1

# Debug mode (smaller dataset, detailed logs)
python train_optimized.py --data_path labeled_dataset --model_id debug --debug --log_level DEBUG

# Quiet mode (minimal console output)
python train_optimized.py --data_path labeled_dataset --model_id production --quiet
```

#### Standard Training

Train using the basic script:

```bash
python main.py --arch TransformerTemporalInverseNet \
               --train labeled_dataset \
               --test labeled_dataset \
               --batch_size 32 \
               --lr 1e-4 \
               --epoch 50 \
               --transformer_layers 3 \
               --d_model 512 \
               --nhead 8 \
               --model_id 1
```

### Key Arguments

- `--arch`: Model architecture (`TransformerTemporalInverseNet` or `TemporalInverseNet`)
- `--train/--test`: Path to training/testing data directories
- `--transformer_layers`: Number of transformer encoder layers
- `--d_model`: Transformer model dimension
- `--nhead`: Number of attention heads
- `--dropout`: Dropout rate
- `--batch_size`: Batch size for training
- `--lr`: Learning rate
- `--epoch`: Number of training epochs

## Data Extraction Tools

### Extract EEG and Source Data Separately

For specialized workflows, you can extract EEG and source data into separate .mat files:

```bash
# Extract all data
python extract_eeg_source_data.py --input_dir labeled_dataset --output_dir extracted_data

# Extract only first 100 samples for testing
python extract_eeg_source_data.py --input_dir labeled_dataset --output_dir extracted_data --max_samples 100 --verify_extraction

# Demo extraction (5 samples)
python demo_extract_data.py
```

**Output Structure:**
```
extracted_data/
‚îú‚îÄ‚îÄ eeg_data/
‚îÇ   ‚îú‚îÄ‚îÄ sample_00000_eeg.mat    # Contains: eeg_data (500√ó75), metadata
‚îÇ   ‚îú‚îÄ‚îÄ sample_00001_eeg.mat
‚îÇ   ‚îî‚îÄ‚îÄ ...
‚îî‚îÄ‚îÄ source_data/
    ‚îú‚îÄ‚îÄ sample_00000_source.mat  # Contains: source_data (500√ó994), metadata
    ‚îú‚îÄ‚îÄ sample_00001_source.mat
    ‚îî‚îÄ‚îÄ ...
```

### Specialized Data Loaders

Use the extracted data format with specialized loaders:

```python
from extracted_data_loader import create_eeg_dataloader, create_source_dataloader, create_paired_dataloader

# EEG-only data loading
eeg_loader = create_eeg_dataloader('extracted_data/eeg_data', batch_size=16)

# Source-only data loading  
source_loader = create_source_dataloader('extracted_data/source_data', batch_size=16)

# Paired EEG-Source data loading
paired_loader = create_paired_dataloader('extracted_data', batch_size=16)

# Test the loaders
python extracted_data_loader.py
```

**Use Cases:**
- Memory-efficient loading when only one data type is needed
- Parallel processing of EEG and source data
- Specialized analysis workflows
- Data preprocessing pipelines

## Source Data Collection Tools

### Consolidate All Source Data (Similar to eval_transformer_real.py)

Collect all source data from your dataset into consolidated "all_data" files:

```bash
# Collect from labeled dataset
python extract_all_source_data.py --data_dir labeled_dataset --output_dir source_collections

# Collect from extracted source data format
python extract_all_source_data.py --data_dir extracted_data/source_data --extracted_format --output_dir source_collections

# Include additional subject directories
python extract_all_source_data.py --data_dir labeled_dataset --subject_dirs real_data test_data --output_prefix all_sources

# Demo collection (quick test)
python demo_source_collection.py
```

**Output Structure:**
```
source_collections/
‚îú‚îÄ‚îÄ all_source_data_labeled_dataset.mat    # Contains: all_data (n_samples, 500, 994)
‚îú‚îÄ‚îÄ all_source_data_real_data.mat          # Contains: all_data, metadata, info
‚îî‚îÄ‚îÄ all_source_data_test_data.mat
```

### Work with Collected Source Data

Use specialized loaders for consolidated source data:

```python
from collected_source_loader import create_multi_collection_dataloader, analyze_collections

# Load multiple collections
loader = create_multi_collection_dataloader('source_collections', batch_size=16)

# Analyze collections
analyze_collections('source_collections')

# Test loaders
python collected_source_loader.py --test
```

**Features:**
- **Consolidated Format**: All source data in single files like eval_transformer_real.py output
- **Multi-Collection Loading**: Load from multiple collection files simultaneously  
- **Preserved Metadata**: Maintains labels, SNR, and other metadata
- **Normalized Data**: Optional data normalization (default: on)
- **Analysis Tools**: Statistics and verification utilities

### Evaluation

#### Comprehensive Evaluation (Recommended)

Evaluate a trained model with full metrics and visualization:

```bash
python eval_real.py --model_path model_result/1_transformer_model/model_best.pth.tar \
                    --data_path labeled_dataset \
                    --output_dir results \
                    --num_samples 100
```

#### Real Data Evaluation (Similar to original DeepSIF)

Evaluate on real EEG data:

```bash
python eval_transformer_real.py --model_id 1 --data_dir real_data  --device cuda:0
```

#### Simulation Data Evaluation (Similar to original DeepSIF)

Evaluate on simulation data with precision/recall metrics:

```bash
python eval_transformer_sim.py --model_id 1 \
                              --test labeled_dataset \
                              --batch_size 32 \
                              --num_samples 200 \
                              --device cuda:0
```

## Model Architecture

### Transformer Temporal Filter

The key innovation is replacing the LSTM temporal module with a Transformer encoder:

- **Input Projection**: Projects EEG features to transformer dimension
- **Positional Encoding**: Adds temporal position information
- **Multi-Head Attention**: Captures temporal dependencies
- **Feed-Forward Networks**: Non-linear transformations
- **Output Projection**: Maps to source space dimensions

### Spatial Filter

Maintains the original MLP-based spatial filtering:
- Two-layer residual MLP for spatial feature extraction
- Configurable activation functions (ELU, ReLU, etc.)

## Enhanced Logging and Monitoring

The optimized training script (`train_optimized.py`) includes comprehensive logging:

### üìù **Logging Features**
- **Real-time progress**: Batch-level updates with loss, gradient norms, and timing
- **System information**: GPU status, memory usage, PyTorch version
- **Data verification**: Loading tests, augmentation confirmation, shape validation
- **Model details**: Architecture summary, parameter counts, initialization status
- **Training health**: Gradient monitoring, learning rate tracking, overfitting detection
- **Performance metrics**: Speed analysis, memory usage, time estimates
- **Automatic saves**: Model checkpoints, training curves, comprehensive history

### üéõÔ∏è **Logging Control**

```bash
# Standard logging (INFO level)
python train_optimized.py --data_path labeled_dataset --model_id standard

# Detailed debugging (DEBUG level)  
python train_optimized.py --data_path labeled_dataset --model_id debug --log_level DEBUG

# Quiet mode (WARNING+ only)
python train_optimized.py --data_path labeled_dataset --model_id quiet --quiet

# Demo logging features
python demo_enhanced_logging.py
```

### üìä **What You Get**
- **Console output**: Real-time training progress with emoji indicators
- **Log file**: Complete detailed log saved to `model_result/{model_id}/training_{model_id}.log`
- **Training curves**: Automatically updated plots during training
- **Health monitoring**: Gradient explosion/vanishing detection
- **Memory tracking**: GPU memory usage alerts
- **Time estimation**: Remaining training time predictions

## Results and Evaluation

The evaluation script provides:

1. **Reconstruction Metrics**:
   - Mean Squared Error (MSE)
   - Temporal correlation between predicted and target signals

2. **Source Localization**:
   - Precision and recall using Otsu thresholding
   - Localization error metrics

3. **Visualization**:
   - Loss and correlation distributions
   - Sample predictions vs targets
   - Source activation maps

## File Descriptions

- `main.py`: Main training script with data loading, model creation, and training loop
- `network.py`: Neural network architectures (Transformer and LSTM variants)
- `loaders.py`: Data loaders for labeled dataset and original DeepSIF format
- `utils.py`: Utility functions for evaluation, noise addition, and data processing
- `eval_real.py`: Comprehensive evaluation script with metrics and visualization
- `eval_transformer_real.py`: Real data evaluation (similar to original DeepSIF eval_real.py)
- `eval_transformer_sim.py`: Simulation data evaluation with precision/recall (similar to original eval_sim.py)
- `demo.py`: Demo script to test implementation with synthetic data
- `test_evaluation.py`: Test script to verify evaluation scripts work correctly

## Comparison with Original DeepSIF

| Feature | Original DeepSIF | DeepSIF Transformer |
|---------|------------------|---------------------|
| Temporal Module | LSTM | Transformer Encoder |
| Data Format | Simulation-based | Labeled dataset |
| Attention | None | Multi-head self-attention |
| Parameters | ~1M | ~2-5M (configurable) |
| Training Speed | Faster | Moderate |
| Performance | Baseline | Improved temporal modeling |

## Configuration Options

### Model Parameters
- `num_sensor`: Number of EEG sensors (default: 75)
- `num_source`: Number of source locations (default: 994)
- `transformer_layers`: Transformer depth (default: 3)
- `d_model`: Model dimension (default: 512)
- `nhead`: Attention heads (default: 8)

### Training Parameters
- Learning rate scheduling
- Batch size optimization
- Dropout for regularization
- Weight decay for L2 regularization

## Troubleshooting

1. **CUDA Memory Issues**: Reduce batch size or model dimensions
2. **Convergence Problems**: Adjust learning rate or add gradient clipping
3. **Data Loading Errors**: Check file paths and .mat file format
4. **Evaluation Errors**: Ensure model and data compatibility

## Future Improvements

- [ ] Add cross-validation support
- [ ] Implement attention visualization
- [ ] Support for different EEG montages
- [ ] Real-time inference capabilities
- [ ] Multi-GPU training support

## Citation

If you use this code, please cite the original DeepSIF paper and this implementation.
